{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29af2848-55b3-40f0-9cb5-d45fc61c4a78",
   "metadata": {},
   "source": [
    "# IA04: The impact of the missing data in Machine Learning\n",
    "\n",
    "Michał Dawid Kowalski (up202401554)\n",
    "\n",
    "A. Develop an empirical analysis on the impact of missing data in machine learning algorithms. You may start by collecting several datasets without missing values and implement some solutions to create different missing mechanisms (MCAR, MAR, and MNAR). Then, select among several approaches to handle missing data (e.g., classifying with missing values, performing data imputation) and compare the obtained classification performance across different approaches. Do the results vary depending on the missing mechanism? Is the top performer in terms of classification metrics also the top performer if the focus shifts towards Predictive or Distributional Accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88cf00b0-afbe-49c3-8cc0-ce85718c2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a5b30-e490-4835-b9a2-be4f884939e6",
   "metadata": {},
   "source": [
    "# 1. **Collecting and Preparing Datasets**\n",
    "\n",
    "At the beginning I chose and preprocess several datasets without missing values (or if they have, dropping these rows) for the future analysis on the impact of missing data in machine learning classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e70c142-0886-48b9-b2c5-6deae4bde3a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1 **Autism Screening Adult Datset**\n",
    "\n",
    "This dataset focuses on **autism screening** for adults, containing 20 features. It includes ten behavioral traits (AQ-10-Adult) and ten personal characteristics. The goal is to identify influential traits and improve ASD classification. It supports research on efficient and accessible ASD screening methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbc81fcf-f57a-4a46-bc12-15a29aebd863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the .arff file\n",
    "data, meta = arff.loadarff('Autism-Adult-Data.arff')\n",
    "\n",
    "# Convert to DataFrame format\n",
    "df_a = pd.DataFrame(data)\n",
    "\n",
    "# Decode byte strings\n",
    "for col in df_a.select_dtypes([object]):\n",
    "    df_a[col] = df_a[col].str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52ffdb44-06e8-4539-9a82-04c56f65f022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 704 entries, 0 to 703\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   A1_Score         704 non-null    object \n",
      " 1   A2_Score         704 non-null    object \n",
      " 2   A3_Score         704 non-null    object \n",
      " 3   A4_Score         704 non-null    object \n",
      " 4   A5_Score         704 non-null    object \n",
      " 5   A6_Score         704 non-null    object \n",
      " 6   A7_Score         704 non-null    object \n",
      " 7   A8_Score         704 non-null    object \n",
      " 8   A9_Score         704 non-null    object \n",
      " 9   A10_Score        704 non-null    object \n",
      " 10  age              702 non-null    float64\n",
      " 11  gender           704 non-null    object \n",
      " 12  ethnicity        704 non-null    object \n",
      " 13  jundice          704 non-null    object \n",
      " 14  austim           704 non-null    object \n",
      " 15  contry_of_res    704 non-null    object \n",
      " 16  used_app_before  704 non-null    object \n",
      " 17  result           704 non-null    float64\n",
      " 18  age_desc         704 non-null    object \n",
      " 19  relation         704 non-null    object \n",
      " 20  Class/ASD        704 non-null    object \n",
      "dtypes: float64(2), object(19)\n",
      "memory usage: 115.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_a.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccdab7bc-8ad9-4d12-8f38-fa94be6bc492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>Latino</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>no</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>m</td>\n",
       "      <td>Latino</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Spain</td>\n",
       "      <td>no</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Parent</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>?</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score  \\\n",
       "0        1        1        1        1        0        0        1        1   \n",
       "1        1        1        0        1        0        0        0        1   \n",
       "2        1        1        0        1        1        0        1        1   \n",
       "3        1        1        0        1        0        0        1        1   \n",
       "4        1        0        0        0        0        0        0        1   \n",
       "\n",
       "  A9_Score A10_Score  ...  gender       ethnicity jundice austim  \\\n",
       "0        0         0  ...       f  White-European      no     no   \n",
       "1        0         1  ...       m          Latino      no    yes   \n",
       "2        1         1  ...       m          Latino     yes    yes   \n",
       "3        0         1  ...       f  White-European      no    yes   \n",
       "4        0         0  ...       f               ?      no     no   \n",
       "\n",
       "   contry_of_res used_app_before result     age_desc relation Class/ASD  \n",
       "0  United States              no    6.0  18 and more     Self        NO  \n",
       "1         Brazil              no    5.0  18 and more     Self        NO  \n",
       "2          Spain              no    8.0  18 and more   Parent       YES  \n",
       "3  United States              no    6.0  18 and more     Self        NO  \n",
       "4          Egypt              no    2.0  18 and more        ?        NO  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3ac63e3-4668-4431-91a7-37db73705cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class/ASD\n",
       "NO     515\n",
       "YES    189\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes distribution\n",
    "df_a['Class/ASD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "101af33b-f879-44fe-ad56-456af385f5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1_Score            0\n",
       "A2_Score            0\n",
       "A3_Score            0\n",
       "A4_Score            0\n",
       "A5_Score            0\n",
       "A6_Score            0\n",
       "A7_Score            0\n",
       "A8_Score            0\n",
       "A9_Score            0\n",
       "A10_Score           0\n",
       "age                 2\n",
       "gender              0\n",
       "ethnicity          95\n",
       "jundice             0\n",
       "austim              0\n",
       "contry_of_res       0\n",
       "used_app_before     0\n",
       "result              0\n",
       "age_desc            0\n",
       "relation           95\n",
       "Class/ASD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df_a.replace(\"?\", np.nan, inplace=True) # Replace '?' to NaN\n",
    "df_a.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07077cf-e6f4-432a-b4cd-92dc33026f8f",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cef66490-be49-4531-879a-f640e746ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df_a.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48e9877b-09f4-4989-85f6-e382a807202f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 21)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.shape # Shape after dropping rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4026f6-90cd-45e9-8cc3-1ce10d3c8472",
   "metadata": {},
   "source": [
    "- After droppin missing values dataset lost 95 records, but still seems to be sufficient for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b9d7812-03b8-4e67-8ed7-933fe5891725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Ax_Score types from object to int\n",
    "score_cols = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', \n",
    "              'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']\n",
    "\n",
    "df_a[score_cols] = df_a[score_cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37bf7e1b-46cb-4942-a3d8-4920e7dd799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant feature 'age_desc'\n",
    "df_a.age_desc.value_counts()\n",
    "df_a = df_a.drop('age_desc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be891d95-ffe0-4cb2-8715-eea6d1dc248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop feature 'result' which leaks the output\n",
    "df_a = df_a.drop('result', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6393e8c8-54d3-4f00-beeb-84b5d6508dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode binary features to 0/1\n",
    "label_encoder = LabelEncoder()\n",
    "df_a['gender'] = label_encoder.fit_transform(df_a['gender'])\n",
    "df_a['jundice'] = label_encoder.fit_transform(df_a['jundice'])\n",
    "df_a['austim'] = label_encoder.fit_transform(df_a['austim'])\n",
    "df_a['used_app_before'] = label_encoder.fit_transform(df_a['used_app_before'])\n",
    "df_a['Class/ASD'] = label_encoder.fit_transform(df_a['Class/ASD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48db817a-2cd2-41fd-8360-5ddb63180f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot Encoding for categorical features\n",
    "df_a = pd.get_dummies(df_a, columns=['ethnicity', 'contry_of_res', 'relation'], drop_first=True)\n",
    "df_a[df_a.select_dtypes('bool').columns] = df_a.select_dtypes('bool').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcc7276d-3a51-4f31-8dae-049b03bb0fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>contry_of_res_Ukraine</th>\n",
       "      <th>contry_of_res_United Arab Emirates</th>\n",
       "      <th>contry_of_res_United Kingdom</th>\n",
       "      <th>contry_of_res_United States</th>\n",
       "      <th>contry_of_res_Uruguay</th>\n",
       "      <th>contry_of_res_Viet Nam</th>\n",
       "      <th>relation_Others</th>\n",
       "      <th>relation_Parent</th>\n",
       "      <th>relation_Relative</th>\n",
       "      <th>relation_Self</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>609.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.740558</td>\n",
       "      <td>0.469622</td>\n",
       "      <td>0.481117</td>\n",
       "      <td>0.520525</td>\n",
       "      <td>0.525452</td>\n",
       "      <td>0.307061</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.665025</td>\n",
       "      <td>0.341544</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.110016</td>\n",
       "      <td>0.124795</td>\n",
       "      <td>0.183908</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>0.082102</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.438689</td>\n",
       "      <td>0.499487</td>\n",
       "      <td>0.500054</td>\n",
       "      <td>0.499989</td>\n",
       "      <td>0.499762</td>\n",
       "      <td>0.461654</td>\n",
       "      <td>0.495278</td>\n",
       "      <td>0.472370</td>\n",
       "      <td>0.474617</td>\n",
       "      <td>0.490765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040522</td>\n",
       "      <td>0.313167</td>\n",
       "      <td>0.330758</td>\n",
       "      <td>0.387728</td>\n",
       "      <td>0.040522</td>\n",
       "      <td>0.090311</td>\n",
       "      <td>0.090311</td>\n",
       "      <td>0.274745</td>\n",
       "      <td>0.209607</td>\n",
       "      <td>0.350215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A1_Score    A2_Score    A3_Score    A4_Score    A5_Score    A6_Score  \\\n",
       "count  609.000000  609.000000  609.000000  609.000000  609.000000  609.000000   \n",
       "mean     0.740558    0.469622    0.481117    0.520525    0.525452    0.307061   \n",
       "std      0.438689    0.499487    0.500054    0.499989    0.499762    0.461654   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "75%      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         A7_Score    A8_Score    A9_Score   A10_Score  ...  \\\n",
       "count  609.000000  609.000000  609.000000  609.000000  ...   \n",
       "mean     0.428571    0.665025    0.341544    0.597701  ...   \n",
       "std      0.495278    0.472370    0.474617    0.490765  ...   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000    0.000000    0.000000  ...   \n",
       "50%      0.000000    1.000000    0.000000    1.000000  ...   \n",
       "75%      1.000000    1.000000    1.000000    1.000000  ...   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...   \n",
       "\n",
       "       contry_of_res_Ukraine  contry_of_res_United Arab Emirates  \\\n",
       "count             609.000000                          609.000000   \n",
       "mean                0.001642                            0.110016   \n",
       "std                 0.040522                            0.313167   \n",
       "min                 0.000000                            0.000000   \n",
       "25%                 0.000000                            0.000000   \n",
       "50%                 0.000000                            0.000000   \n",
       "75%                 0.000000                            0.000000   \n",
       "max                 1.000000                            1.000000   \n",
       "\n",
       "       contry_of_res_United Kingdom  contry_of_res_United States  \\\n",
       "count                    609.000000                   609.000000   \n",
       "mean                       0.124795                     0.183908   \n",
       "std                        0.330758                     0.387728   \n",
       "min                        0.000000                     0.000000   \n",
       "25%                        0.000000                     0.000000   \n",
       "50%                        0.000000                     0.000000   \n",
       "75%                        0.000000                     0.000000   \n",
       "max                        1.000000                     1.000000   \n",
       "\n",
       "       contry_of_res_Uruguay  contry_of_res_Viet Nam  relation_Others  \\\n",
       "count             609.000000              609.000000       609.000000   \n",
       "mean                0.001642                0.008210         0.008210   \n",
       "std                 0.040522                0.090311         0.090311   \n",
       "min                 0.000000                0.000000         0.000000   \n",
       "25%                 0.000000                0.000000         0.000000   \n",
       "50%                 0.000000                0.000000         0.000000   \n",
       "75%                 0.000000                0.000000         0.000000   \n",
       "max                 1.000000                1.000000         1.000000   \n",
       "\n",
       "       relation_Parent  relation_Relative  relation_Self  \n",
       "count       609.000000         609.000000     609.000000  \n",
       "mean          0.082102           0.045977       0.857143  \n",
       "std           0.274745           0.209607       0.350215  \n",
       "min           0.000000           0.000000       0.000000  \n",
       "25%           0.000000           0.000000       1.000000  \n",
       "50%           0.000000           0.000000       1.000000  \n",
       "75%           0.000000           0.000000       1.000000  \n",
       "max           1.000000           1.000000       1.000000  \n",
       "\n",
       "[8 rows x 89 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical Characteristics\n",
    "df_a.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "640c2a2c-5c4d-4d7f-be76-4eff44d32c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = df_a.drop('Class/ASD', axis=1)\n",
    "y_a = df_a['Class/ASD']\n",
    "\n",
    "# Train Test Split 70/30, because dataset is relatively small with just 214 instances\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_a, y_a, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52fde062-4ead-4318-8896-e3d917f52c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features using MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X_train_a)\n",
    "X_train_a = pd.DataFrame(scaler.transform(X_train_a), columns=X_train_a.columns)\n",
    "X_test_a = pd.DataFrame(scaler.transform(X_test_a), columns=X_test_a.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f2d8c-a860-4349-816b-0549ed4974f3",
   "metadata": {},
   "source": [
    "## 1.2 **Mushroom Dataset**\n",
    "\n",
    "This dataset contains cleaned and preprocessed information about mushrooms, including features like cap diameter, shape, and stem color, for binary classification of edibility. The target class indicates whether the mushroom is edible or poisonous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c48f705c-fcd7-4a4a-bd4e-5d92cb819d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from the file\n",
    "df_m = pd.read_csv('mushroom_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c10ea34e-7cbf-4dce-bedb-5efed718ce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54035 entries, 0 to 54034\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   cap-diameter     54035 non-null  int64  \n",
      " 1   cap-shape        54035 non-null  int64  \n",
      " 2   gill-attachment  54035 non-null  int64  \n",
      " 3   gill-color       54035 non-null  int64  \n",
      " 4   stem-height      54035 non-null  float64\n",
      " 5   stem-width       54035 non-null  int64  \n",
      " 6   stem-color       54035 non-null  int64  \n",
      " 7   season           54035 non-null  float64\n",
      " 8   class            54035 non-null  int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Dataset info\n",
    "df_m.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "524d3672-ca93-4c1f-8308-7f79e4feb09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>season</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1545</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1461</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1557</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1371</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.612496</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.787572</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.711971</td>\n",
       "      <td>1464</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
       "0          1372          2                2          10     3.807467   \n",
       "1          1461          2                2          10     3.807467   \n",
       "2          1371          2                2          10     3.612496   \n",
       "3          1261          6                2          10     3.787572   \n",
       "4          1305          6                2          10     3.711971   \n",
       "\n",
       "   stem-width  stem-color    season  class  \n",
       "0        1545          11  1.804273      1  \n",
       "1        1557          11  1.804273      1  \n",
       "2        1566          11  1.804273      1  \n",
       "3        1566          11  1.804273      1  \n",
       "4        1464          11  0.943195      1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Dataframe\n",
    "df_m.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c7e7dcd-7709-4975-9ae1-fbc9906b61bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    29675\n",
       "0    24360\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes Distribution\n",
    "df_m['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b18a774-5c48-41be-80db-8108a79aed1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cap-diameter       0\n",
       "cap-shape          0\n",
       "gill-attachment    0\n",
       "gill-color         0\n",
       "stem-height        0\n",
       "stem-width         0\n",
       "stem-color         0\n",
       "season             0\n",
       "class              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df_m.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf252861-d56d-4945-be9f-817c1e9ebcbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>season</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54035.000000</td>\n",
       "      <td>54035.000000</td>\n",
       "      <td>54035.000000</td>\n",
       "      <td>54035.000000</td>\n",
       "      <td>54035.000000</td>\n",
       "      <td>54035.000000</td>\n",
       "      <td>54035.000000</td>\n",
       "      <td>54035.000000</td>\n",
       "      <td>54035.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>567.257204</td>\n",
       "      <td>4.000315</td>\n",
       "      <td>2.142056</td>\n",
       "      <td>7.329509</td>\n",
       "      <td>0.759110</td>\n",
       "      <td>1051.081299</td>\n",
       "      <td>8.418062</td>\n",
       "      <td>0.952163</td>\n",
       "      <td>0.549181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>359.883763</td>\n",
       "      <td>2.160505</td>\n",
       "      <td>2.228821</td>\n",
       "      <td>3.200266</td>\n",
       "      <td>0.650969</td>\n",
       "      <td>782.056076</td>\n",
       "      <td>3.262078</td>\n",
       "      <td>0.305594</td>\n",
       "      <td>0.497580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>289.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.270997</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.888450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>525.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.593295</td>\n",
       "      <td>923.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.943195</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>781.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.054858</td>\n",
       "      <td>1523.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.943195</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1891.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.835320</td>\n",
       "      <td>3569.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cap-diameter     cap-shape  gill-attachment    gill-color  \\\n",
       "count  54035.000000  54035.000000     54035.000000  54035.000000   \n",
       "mean     567.257204      4.000315         2.142056      7.329509   \n",
       "std      359.883763      2.160505         2.228821      3.200266   \n",
       "min        0.000000      0.000000         0.000000      0.000000   \n",
       "25%      289.000000      2.000000         0.000000      5.000000   \n",
       "50%      525.000000      5.000000         1.000000      8.000000   \n",
       "75%      781.000000      6.000000         4.000000     10.000000   \n",
       "max     1891.000000      6.000000         6.000000     11.000000   \n",
       "\n",
       "        stem-height    stem-width    stem-color        season         class  \n",
       "count  54035.000000  54035.000000  54035.000000  54035.000000  54035.000000  \n",
       "mean       0.759110   1051.081299      8.418062      0.952163      0.549181  \n",
       "std        0.650969    782.056076      3.262078      0.305594      0.497580  \n",
       "min        0.000426      0.000000      0.000000      0.027372      0.000000  \n",
       "25%        0.270997    421.000000      6.000000      0.888450      0.000000  \n",
       "50%        0.593295    923.000000     11.000000      0.943195      1.000000  \n",
       "75%        1.054858   1523.000000     11.000000      0.943195      1.000000  \n",
       "max        3.835320   3569.000000     12.000000      1.804273      1.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical Characteristics\n",
    "df_m.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fc8c486-e8ac-4581-9691-2b8f377c93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_m = df_m.drop('class', axis=1)\n",
    "y_m = df_m['class']\n",
    "\n",
    "# Train Test Split 80/30, because dataset is relatively big\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_m, y_m, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbd562d4-4733-4f5d-a2ed-e27ba445470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features using MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X_train_m)\n",
    "X_train_m = pd.DataFrame(scaler.transform(X_train_m), columns=X_train_m.columns)\n",
    "X_test_m = pd.DataFrame(scaler.transform(X_test_m), columns=X_test_m.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f51ab-1e63-43cb-90dc-3adbb295cdb6",
   "metadata": {},
   "source": [
    "## 1.3 **Occupancy Detection Dataset**\n",
    "\n",
    "This dataset specifies Accurate Occupancy Detection of an office room from light, temperature, humidity, and CO2 measurements. It contains 20,560 instances and 6 features, used for binary classification to predict room occupancy.\n",
    "\n",
    "\n",
    "Info: The dataset is already split into training and test files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32977c98-b168-4508-a0f5-67be75d57ec4",
   "metadata": {},
   "source": [
    "### 1.3.1 Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b837ddeb-e1d4-439d-b6b4-6760de8dbbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training dataset\n",
    "df_o = pd.read_csv('datatraining.txt', header=0, quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c59cf38-db6f-492a-8f78-6abf132f2b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-04 17:51:00</td>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-04 17:51:59</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-04 17:53:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-04 17:54:00</td>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-02-04 17:55:00</td>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  Temperature  Humidity  Light     CO2  HumidityRatio  \\\n",
       "1  2015-02-04 17:51:00        23.18   27.2720  426.0  721.25       0.004793   \n",
       "2  2015-02-04 17:51:59        23.15   27.2675  429.5  714.00       0.004783   \n",
       "3  2015-02-04 17:53:00        23.15   27.2450  426.0  713.50       0.004779   \n",
       "4  2015-02-04 17:54:00        23.15   27.2000  426.0  708.25       0.004772   \n",
       "5  2015-02-04 17:55:00        23.10   27.2000  426.0  704.50       0.004757   \n",
       "\n",
       "   Occupancy  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "5          1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display dataset\n",
    "df_o.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a96a508-a18a-459e-829c-a4d34e5ca877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (8143, 7)\n"
     ]
    }
   ],
   "source": [
    "# Dataset Shape\n",
    "print(f'Training dataset shape: {df_o.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06913987-ea56-43da-99ca-a684eb2f02d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8143 entries, 1 to 8143\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           8143 non-null   object \n",
      " 1   Temperature    8143 non-null   float64\n",
      " 2   Humidity       8143 non-null   float64\n",
      " 3   Light          8143 non-null   float64\n",
      " 4   CO2            8143 non-null   float64\n",
      " 5   HumidityRatio  8143 non-null   float64\n",
      " 6   Occupancy      8143 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 508.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dataset info\n",
    "df_o.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6fdc38ad-a5e5-42a6-aea3-bd0edaa45776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Occupancy\n",
       "0    6414\n",
       "1    1729\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classes distribution\n",
    "df_o['Occupancy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "050e6a62-7630-496c-84f1-6614b99896a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             0\n",
       "Temperature      0\n",
       "Humidity         0\n",
       "Light            0\n",
       "CO2              0\n",
       "HumidityRatio    0\n",
       "Occupancy        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df_o.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35173e02-b21b-499f-ab60-eb1a5190a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant features from the datetime\n",
    "def features_datetime(df):\n",
    "    df['date'] = pd.to_datetime(df['date']) # Convert into datetime format\n",
    "    df['hour'] = df['date'].dt.hour # Extract hour\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek # Extract day of the week where: Monday=0 ...  Sunday=6\n",
    "    df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "features_datetime(df_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a25fb47a-a407-4a17-b5c4-658834e2bf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.18</td>\n",
       "      <td>27.2720</td>\n",
       "      <td>426.0</td>\n",
       "      <td>721.25</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2675</td>\n",
       "      <td>429.5</td>\n",
       "      <td>714.00</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2450</td>\n",
       "      <td>426.0</td>\n",
       "      <td>713.50</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.15</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>708.25</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.10</td>\n",
       "      <td>27.2000</td>\n",
       "      <td>426.0</td>\n",
       "      <td>704.50</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Light     CO2  HumidityRatio  Occupancy  hour  \\\n",
       "1        23.18   27.2720  426.0  721.25       0.004793          1    17   \n",
       "2        23.15   27.2675  429.5  714.00       0.004783          1    17   \n",
       "3        23.15   27.2450  426.0  713.50       0.004779          1    17   \n",
       "4        23.15   27.2000  426.0  708.25       0.004772          1    17   \n",
       "5        23.10   27.2000  426.0  704.50       0.004757          1    17   \n",
       "\n",
       "   day_of_week  \n",
       "1            2  \n",
       "2            2  \n",
       "3            2  \n",
       "4            2  \n",
       "5            2  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display dataset after features extraction\n",
    "df_o.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6b5e3f1-f6b0-40f6-8d93-eb06f04da07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Characteristics:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Light</th>\n",
       "      <th>CO2</th>\n",
       "      <th>HumidityRatio</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.619084</td>\n",
       "      <td>25.731507</td>\n",
       "      <td>119.519375</td>\n",
       "      <td>606.546243</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>0.212330</td>\n",
       "      <td>11.390642</td>\n",
       "      <td>3.344222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.016916</td>\n",
       "      <td>5.531211</td>\n",
       "      <td>194.755805</td>\n",
       "      <td>314.320877</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.408982</td>\n",
       "      <td>7.092195</td>\n",
       "      <td>2.067996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>16.745000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>412.750000</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.700000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>0.003078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.390000</td>\n",
       "      <td>26.222500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>453.500000</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.390000</td>\n",
       "      <td>30.533333</td>\n",
       "      <td>256.375000</td>\n",
       "      <td>638.833333</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.180000</td>\n",
       "      <td>39.117500</td>\n",
       "      <td>1546.333333</td>\n",
       "      <td>2028.500000</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature     Humidity        Light          CO2  HumidityRatio  \\\n",
       "count  8143.000000  8143.000000  8143.000000  8143.000000    8143.000000   \n",
       "mean     20.619084    25.731507   119.519375   606.546243       0.003863   \n",
       "std       1.016916     5.531211   194.755805   314.320877       0.000852   \n",
       "min      19.000000    16.745000     0.000000   412.750000       0.002674   \n",
       "25%      19.700000    20.200000     0.000000   439.000000       0.003078   \n",
       "50%      20.390000    26.222500     0.000000   453.500000       0.003801   \n",
       "75%      21.390000    30.533333   256.375000   638.833333       0.004352   \n",
       "max      23.180000    39.117500  1546.333333  2028.500000       0.006476   \n",
       "\n",
       "         Occupancy         hour  day_of_week  \n",
       "count  8143.000000  8143.000000  8143.000000  \n",
       "mean      0.212330    11.390642     3.344222  \n",
       "std       0.408982     7.092195     2.067996  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.000000     5.000000     2.000000  \n",
       "50%       0.000000    11.000000     4.000000  \n",
       "75%       0.000000    18.000000     5.000000  \n",
       "max       1.000000    23.000000     6.000000  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistical Characteristics\n",
    "print('Statistical Characteristics:\\n')\n",
    "df_o.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "300a40de-8b8a-421c-a41d-cd58691938e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Input and Labels\n",
    "X_train_o = df_o.drop('Occupancy', axis=1)\n",
    "y_train_o = df_o['Occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56a023c2-2b4f-4d13-9c13-38a8ffd0634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features using MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X_train_o)\n",
    "X_train_o = pd.DataFrame(scaler.transform(X_train_o), columns=X_train_o.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebefad-06e7-47a0-87fa-2f8fc04417c8",
   "metadata": {},
   "source": [
    "### 1.3.2 Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e51a27e-e4ad-4712-bfbb-4b6ba738dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test dataset\n",
    "df_o_test = pd.read_csv('datatest.txt', header=0, quotechar='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4132f9d4-dda3-4a52-a3bb-90eb7619358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset shape: (2665, 7)\n"
     ]
    }
   ],
   "source": [
    "# Dataset Shape\n",
    "print(f'Test dataset shape: {df_o_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6b7b5213-47fb-4c5c-bac9-b204479d73ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2665 entries, 140 to 2804\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           2665 non-null   object \n",
      " 1   Temperature    2665 non-null   float64\n",
      " 2   Humidity       2665 non-null   float64\n",
      " 3   Light          2665 non-null   float64\n",
      " 4   CO2            2665 non-null   float64\n",
      " 5   HumidityRatio  2665 non-null   float64\n",
      " 6   Occupancy      2665 non-null   int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 166.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dataset info\n",
    "df_o_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e3a2b379-4679-429f-8996-1a17c29029f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             0\n",
       "Temperature      0\n",
       "Humidity         0\n",
       "Light            0\n",
       "CO2              0\n",
       "HumidityRatio    0\n",
       "Occupancy        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df_o_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "57729566-0709-420b-986f-51b9b4fc539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features extraction\n",
    "features_datetime(df_o_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "934d99af-c4ad-4e4f-9a9d-acdeb19fa969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Input and Labels\n",
    "X_test_o = df_o_test.drop('Occupancy', axis=1)\n",
    "y_test_o = df_o_test['Occupancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa98ae3a-8f20-49ed-9d08-8f2d77052d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features using MinMaxScaler\n",
    "X_test_o = pd.DataFrame(scaler.transform(X_test_o), columns=X_test_o.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a41b3-7f57-44df-bb5b-2555d4db790a",
   "metadata": {},
   "source": [
    "# 2. **Simulating Missing Values**\n",
    "\n",
    "There are 3 possible mechanisms which lead to the missing values introdution: MCAR, MAR, MNAR. Short description below:\n",
    "\n",
    "- **MCAR** (Missing Completely At Random): missing data is unrelated to other measured variables and unrelated to its values\n",
    "- **MAR** (Missing At Random): missing data is related to some other measured variables and not related to its values\n",
    "- **MNAR** (Missing Not At Random): missing data is not related to other measured variables, but related to its values\n",
    "\n",
    "## 2.1 **Mechanisms Functions**\n",
    "\n",
    "In this step I applied mentioned mechanisms, generating 3 variants of sets for each of my datasets. Those sets will become a base for developing the assignment case analysis. For this reason I used **mdatagen** Python library, which is a tool for artificial generation of the missing data in a controlled way consistent with MCAR, MAR and MNAR.\n",
    "\n",
    "I focused my experiments exclusively on **univariate** missing value generators, where only one feature contains missing values. Moreover, the feature selected will be the one with the highest correlation to the target. Missing rate will be set during the experiment execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bdf99821-5d6e-4463-b33b-6b3a785ddfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdatagen.univariate.uMAR import uMAR\n",
    "from mdatagen.univariate.uMNAR import uMNAR\n",
    "from mdatagen.univariate.uMCAR import uMCAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd97d9b4-9148-47cf-9b2c-8ceb27ef7278",
   "metadata": {},
   "source": [
    "### 2.1.1 MCAR Function\n",
    "- method=\"correlated\" chooses the most correlated feature with a target\n",
    "- randomly sets missing values in the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "34869775-8f42-4761-86a1-f5b096010035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate MCAR Mechanism\n",
    "def MCAR(X, y, missing_rate):\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = np.array(y)\n",
    "    # Set the generator\n",
    "    generator = uMCAR(X=X,\n",
    "                      y=y,\n",
    "                      missing_rate=missing_rate,\n",
    "                      method=\"correlated\")\n",
    "    # Generate the missing data under MCAR mechanism\n",
    "    generate_data = generator.random()\n",
    "    # Return new dataset with missing values\n",
    "    return generate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65459aac-4e4d-49ed-8cd3-f5558c0548e9",
   "metadata": {},
   "source": [
    "### 2.1.2 MAR Function\n",
    "- the most correlated two features with a target will become x_miss (receives missing values) and x_obs (observed feature)\n",
    "- mix() generates missing values in the feature using the N/2 lowest values and N/2 highest values from an observed feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "680fc23a-8f52-4649-97c4-815513538ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate MAR Mechanism\n",
    "def MAR(X, y, missing_rate):\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = np.array(y)\n",
    "    # Set the generator\n",
    "    generator = uMAR(X=X,\n",
    "                     y=y,\n",
    "                     missing_rate=missing_rate)\n",
    "    # Generate the missing data under MAR mechanism\n",
    "    generate_data = generator.mix()\n",
    "    # Return new dataset with missing values\n",
    "    return generate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da36f4-fc65-465e-abd5-c8d14c4c0630",
   "metadata": {},
   "source": [
    "### 2.1.3 MNAR Function\n",
    "\n",
    "- the most correlated feature with a target will receive missing values\n",
    "- threshold=0.8 means that missing values will be introduced into the observations with the highest 80% of values in the chosen feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "09d721b4-f40a-4adb-ada8-592d3fc6c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate MNAR Mechanism \n",
    "def MNAR(X, y, missing_rate):\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = np.array(y)\n",
    "    # Set the generator\n",
    "    generator = uMNAR(X=X,\n",
    "                      y=y,\n",
    "                      missing_rate=missing_rate,\n",
    "                      threshold = 0.8)\n",
    "    # Generate the missing data under MNAR mechanism\n",
    "    generate_data = generator.run()\n",
    "    # Return new dataset with missing values\n",
    "    return generate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56efed-f584-49db-9809-8f16a3a18bf0",
   "metadata": {},
   "source": [
    "## 2.2 **Generating Datasets with Missing Values**\n",
    "\n",
    "Now it's turn to use MCAR, MAR and MNAR functions to generate datasets with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "61e1b21f-8ddc-40b8-b688-b2e6e95db21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rate=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e5f058-5d56-4210-837a-8a2a46195ced",
   "metadata": {},
   "source": [
    "### 2.2.1 Autism Screening Adult Datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7758103c-354a-4efa-a526-7ea19528e63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values percentage:\n",
      "A9_Score    50.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Generating datasets with missing values but different mechanisms\n",
    "X_MCAR_a = MCAR(X_train_a, y_train_a, missing_rate) # MCAR\n",
    "X_MCAR_a = X_MCAR_a.drop('target', axis=1)\n",
    "X_MAR_a = MAR(X_train_a, y_train_a, missing_rate) # MAR\n",
    "X_MAR_a = X_MAR_a.drop('target', axis=1)\n",
    "X_MNAR_a = MNAR(X_train_a, y_train_a, missing_rate) # MNAR\n",
    "X_MNAR_a = X_MNAR_a.drop('target', axis=1)\n",
    "\n",
    "missing_percentage = X_MCAR_a.isnull().mean() * 100\n",
    "print(\"Missing values percentage:\")\n",
    "print(missing_percentage[missing_percentage > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89da36c-be0d-4d2b-8b4c-309fc2844df8",
   "metadata": {},
   "source": [
    "### 2.2.2 Mushroom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "759a191e-4b5e-45bf-b6b2-2e4a2337bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values percentage:\n",
      "stem-height    50.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Generating datasets with missing values but different mechanisms\n",
    "X_MCAR_m = MCAR(X_train_m, y_train_m, missing_rate) # MCAR\n",
    "X_MCAR_m = X_MCAR_m.drop('target', axis=1)\n",
    "X_MAR_m = MAR(X_train_m, y_train_m, missing_rate) # MAR\n",
    "X_MAR_m = X_MAR_m.drop('target', axis=1)\n",
    "X_MNAR_m = MNAR(X_train_m, y_train_m, missing_rate) # MNAR\n",
    "X_MNAR_m = X_MNAR_m.drop('target', axis=1)\n",
    "\n",
    "missing_percentage = X_MCAR_m.isnull().mean() * 100\n",
    "print(\"Missing values percentage:\")\n",
    "print(missing_percentage[missing_percentage > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e495bb-f340-4e2b-bfc3-08aceaa318c7",
   "metadata": {},
   "source": [
    "### 2.2.3 Occupancy Detection Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d38e1966-4185-4e28-8f4e-7312ade798d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values percentage:\n",
      "Light    50.00614\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Generating datasets with missing values but different mechanisms\n",
    "X_MCAR_o = MCAR(X_train_o, y_train_o, missing_rate) # MCAR\n",
    "X_MCAR_o = X_MCAR_o.drop('target', axis=1)\n",
    "X_MAR_o = MAR(X_train_o, y_train_o, missing_rate) # MAR\n",
    "X_MAR_o = X_MAR_o.drop('target', axis=1)\n",
    "X_MNAR_o = MNAR(X_train_o, y_train_o, missing_rate) # MNAR\n",
    "X_MNAR_o = X_MNAR_o.drop('target', axis=1)\n",
    "\n",
    "missing_percentage = X_MCAR_o.isnull().mean() * 100\n",
    "print(\"Missing values percentage:\")\n",
    "print(missing_percentage[missing_percentage > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe389a-dfc6-45c6-a762-6350dc8d4c3f",
   "metadata": {},
   "source": [
    "# 3. **Classifying with Missing Values using Random Forest**\n",
    "\n",
    "To evaluate the impact of missing data on classification, the **Random Forest** classifier was chosen for its ability to handle missing values during splits. Performance was measured using precision, recall, F1-score, and accuracy both for complete datasets and datasets with missing mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a2b86bb1-13a8-45dd-a734-54b86c9d8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "def run_random_forest(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return y_pred, report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc32cc-a204-48da-8a8d-0d0397cd9574",
   "metadata": {},
   "source": [
    "### 3.1 Autism Screening Adult Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33960dc1-b76d-4bce-909e-acb34cad9533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95       126\n",
      "           1       0.92      0.82      0.87        57\n",
      "\n",
      "    accuracy                           0.92       183\n",
      "   macro avg       0.92      0.90      0.91       183\n",
      "weighted avg       0.92      0.92      0.92       183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset before generating missing values \n",
    "y_pred, report = run_random_forest(X_train_a, X_test_a, y_train_a, y_test_a)\n",
    "print('Results:\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1736,
   "id": "0ff1593b-cf41-4aff-a7c8-914525e59e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       146\n",
      "           1       0.92      0.91      0.91        65\n",
      "\n",
      "    accuracy                           0.95       211\n",
      "   macro avg       0.94      0.94      0.94       211\n",
      "weighted avg       0.95      0.95      0.95       211\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       146\n",
      "           1       0.97      0.88      0.92        65\n",
      "\n",
      "    accuracy                           0.95       211\n",
      "   macro avg       0.96      0.93      0.94       211\n",
      "weighted avg       0.95      0.95      0.95       211\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       146\n",
      "           1       0.92      0.91      0.91        65\n",
      "\n",
      "    accuracy                           0.95       211\n",
      "   macro avg       0.94      0.94      0.94       211\n",
      "weighted avg       0.95      0.95      0.95       211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MCAR\n",
    "y_pred, report = run_random_forest(X_MCAR_a, X_test_a, y_train_a, y_test_a)\n",
    "print('MCAR Results:\\n')\n",
    "print(report)\n",
    "# MAR\n",
    "y_pred, report = run_random_forest(X_MAR_a, X_test_a, y_train_a, y_test_a)\n",
    "print('MAR Results:\\n')\n",
    "print(report)\n",
    "# MNAR\n",
    "y_pred, report = run_random_forest(X_MNAR_a, X_test_a, y_train_a, y_test_a)\n",
    "print('MNAR Results:\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c729-28a4-4c84-b834-e269901e679c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.2 Mushroom Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "86bf383a-42e0-4983-b080-b3e08ab5896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4909\n",
      "           1       0.99      0.99      0.99      5898\n",
      "\n",
      "    accuracy                           0.99     10807\n",
      "   macro avg       0.99      0.99      0.99     10807\n",
      "weighted avg       0.99      0.99      0.99     10807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset before generating missing values \n",
    "y_pred, report = run_random_forest(X_train_m, X_test_m, y_train_m, y_test_m)\n",
    "print('Results:\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b8915be0-c8d6-4fdc-9e97-77d703838167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4909\n",
      "           1       0.99      0.99      0.99      5898\n",
      "\n",
      "    accuracy                           0.99     10807\n",
      "   macro avg       0.99      0.99      0.99     10807\n",
      "weighted avg       0.99      0.99      0.99     10807\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      4909\n",
      "           1       0.99      0.98      0.99      5898\n",
      "\n",
      "    accuracy                           0.98     10807\n",
      "   macro avg       0.98      0.98      0.98     10807\n",
      "weighted avg       0.98      0.98      0.98     10807\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4909\n",
      "           1       0.99      0.97      0.98      5898\n",
      "\n",
      "    accuracy                           0.98     10807\n",
      "   macro avg       0.98      0.98      0.98     10807\n",
      "weighted avg       0.98      0.98      0.98     10807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MCAR\n",
    "y_pred, report = run_random_forest(X_MCAR_m, X_test_m, y_train_m, y_test_m)\n",
    "print('MCAR Results:\\n')\n",
    "print(report)\n",
    "# MAR\n",
    "y_pred, report = run_random_forest(X_MAR_m, X_test_m, y_train_m, y_test_m)\n",
    "print('MAR Results:\\n')\n",
    "print(report)\n",
    "# MNAR\n",
    "y_pred, report = run_random_forest(X_MNAR_m, X_test_m, y_train_m, y_test_m)\n",
    "print('MNAR Results:\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4c1a9f-6aad-433b-ba8a-065449effebe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.3 Occupancy Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "458de51e-9680-453e-aa1a-fb2e929033f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1693\n",
      "           1       0.95      0.94      0.94       972\n",
      "\n",
      "    accuracy                           0.96      2665\n",
      "   macro avg       0.96      0.96      0.96      2665\n",
      "weighted avg       0.96      0.96      0.96      2665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset before generating missing values \n",
    "y_pred, report = run_random_forest(X_train_o, X_test_o, y_train_o, y_test_o)\n",
    "print('Results:\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1682,
   "id": "7534315c-48ce-460a-9c7f-361c40bb257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1693\n",
      "           1       0.95      0.94      0.95       972\n",
      "\n",
      "    accuracy                           0.96      2665\n",
      "   macro avg       0.96      0.96      0.96      2665\n",
      "weighted avg       0.96      0.96      0.96      2665\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1693\n",
      "           1       0.95      0.94      0.94       972\n",
      "\n",
      "    accuracy                           0.96      2665\n",
      "   macro avg       0.96      0.96      0.96      2665\n",
      "weighted avg       0.96      0.96      0.96      2665\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1693\n",
      "           1       0.93      0.92      0.92       972\n",
      "\n",
      "    accuracy                           0.94      2665\n",
      "   macro avg       0.94      0.94      0.94      2665\n",
      "weighted avg       0.94      0.94      0.94      2665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MCAR\n",
    "y_pred, report = run_random_forest(X_MCAR_o, X_test_o, y_train_o, y_test_o)\n",
    "print('MCAR Results:\\n')\n",
    "print(report)\n",
    "# MAR\n",
    "y_pred, report = run_random_forest(X_MAR_o, X_test_o, y_train_o, y_test_o)\n",
    "print('MAR Results:\\n')\n",
    "print(report)\n",
    "# MNAR\n",
    "y_pred, report = run_random_forest(X_MNAR_o, X_test_o, y_train_o, y_test_o)\n",
    "print('MNAR Results:\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a22fb9-a39f-4458-9e29-75d0d46aa1bc",
   "metadata": {},
   "source": [
    "# 4. **Handling Missing Values with Data Imputation**\n",
    "\n",
    "In this part I present various approaches to handle and recover missing values by using imputation strategies in datasets. The **SVM** classifier with an RBF kernel was evaluated using imputation strategies like: **Statistical Imputation, KNN Imputation, and Multiple Imputation (MICE)** with sklearn tools. Also, the **Predective Accuracy** was evaluated by estimating **Mean Abolute Error** (MAE) to assess how accurately imputers replace missing data comparing to a actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "fcb6e657-b0f7-4467-bac5-282e530707ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classificator\n",
    "def run_svm(X_miss, X_train, X_test, y_train, y_test, imputer):\n",
    "    X_miss = pd.DataFrame(imputer.fit_transform(X_miss), columns=X_miss.columns)\n",
    "    \n",
    "    clf = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "    clf.fit(X_miss, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, zero_division=1)   \n",
    "\n",
    "    mae = mean_absolute_error(X_train, X_miss)\n",
    "    \n",
    "    return y_pred, report, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9f06f-6a4a-4c55-baed-01fb3bab1579",
   "metadata": {},
   "source": [
    "## 4.1 **Statistical Imputation**\n",
    "Statistical imputation replaces missing values with statistical measures, in this case the mean and median of the respective feature, providing a simple approach to handle missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d66824-813e-4145-8224-57d56c7a38d2",
   "metadata": {},
   "source": [
    "### 4.1.1 Autism Screening Adult Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee0ef3-fe62-434d-aff5-0731a2137329",
   "metadata": {},
   "source": [
    "**- MEAN IMPUTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "7a1cbac1-2c90-42e9-9356-fc2ceff18b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       126\n",
      "           1       0.95      0.93      0.94        57\n",
      "\n",
      "    accuracy                           0.96       183\n",
      "   macro avg       0.96      0.95      0.96       183\n",
      "weighted avg       0.96      0.96      0.96       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0025\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       126\n",
      "           1       0.95      0.93      0.94        57\n",
      "\n",
      "    accuracy                           0.96       183\n",
      "   macro avg       0.96      0.95      0.96       183\n",
      "weighted avg       0.96      0.96      0.96       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0026\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       126\n",
      "           1       0.96      0.84      0.90        57\n",
      "\n",
      "    accuracy                           0.94       183\n",
      "   macro avg       0.95      0.91      0.93       183\n",
      "weighted avg       0.94      0.94      0.94       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_a, X_train_a, X_test_a, y_train_a, y_test_a, mean_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_a, X_train_a, X_test_a, y_train_a, y_test_a, mean_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_a, X_train_a, X_test_a, y_train_a, y_test_a, mean_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f9b127-aff2-47d2-bfd5-6f39f77c5335",
   "metadata": {},
   "source": [
    "**- MODE IMPUTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "0844465b-adda-41f7-ad18-3058af543057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       126\n",
      "           1       0.93      0.98      0.96        57\n",
      "\n",
      "    accuracy                           0.97       183\n",
      "   macro avg       0.96      0.98      0.97       183\n",
      "weighted avg       0.97      0.97      0.97       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0020\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       126\n",
      "           1       0.96      0.95      0.96        57\n",
      "\n",
      "    accuracy                           0.97       183\n",
      "   macro avg       0.97      0.97      0.97       183\n",
      "weighted avg       0.97      0.97      0.97       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0025\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       126\n",
      "           1       0.96      0.84      0.90        57\n",
      "\n",
      "    accuracy                           0.94       183\n",
      "   macro avg       0.95      0.91      0.93       183\n",
      "weighted avg       0.94      0.94      0.94       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_a, X_train_a, X_test_a, y_train_a, y_test_a, median_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_a, X_train_a, X_test_a, y_train_a, y_test_a, median_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_a, X_train_a, X_test_a, y_train_a, y_test_a, median_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80942da4-b037-4c2a-b21a-725f1b8a0e69",
   "metadata": {},
   "source": [
    "### 4.1.2 Mushroom Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935b950-5269-485d-ba8a-005f603913a3",
   "metadata": {},
   "source": [
    "**- MEAN IMPUTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "a8696f94-c629-46b1-874e-2e92a945bca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4909\n",
      "           1       0.87      0.87      0.87      5898\n",
      "\n",
      "    accuracy                           0.86     10807\n",
      "   macro avg       0.86      0.86      0.86     10807\n",
      "weighted avg       0.86      0.86      0.86     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0081\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83      4909\n",
      "           1       0.84      0.88      0.86      5898\n",
      "\n",
      "    accuracy                           0.85     10807\n",
      "   macro avg       0.85      0.84      0.84     10807\n",
      "weighted avg       0.85      0.85      0.85     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0079\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78      4909\n",
      "           1       0.79      0.89      0.84      5898\n",
      "\n",
      "    accuracy                           0.81     10807\n",
      "   macro avg       0.82      0.81      0.81     10807\n",
      "weighted avg       0.82      0.81      0.81     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_m, X_train_m, X_test_m, y_train_m, y_test_m, mean_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_m, X_train_m, X_test_m, y_train_m, y_test_m, mean_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_m, X_train_m, X_test_m, y_train_m, y_test_m, mean_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688185a5-d858-4812-b080-d3119878b0ba",
   "metadata": {},
   "source": [
    "**- MEDIAN IMPUTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "e3cc907a-3371-48bd-8d10-21673e4dc8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      4909\n",
      "           1       0.86      0.88      0.87      5898\n",
      "\n",
      "    accuracy                           0.86     10807\n",
      "   macro avg       0.86      0.86      0.86     10807\n",
      "weighted avg       0.86      0.86      0.86     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0078\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80      4909\n",
      "           1       0.81      0.89      0.85      5898\n",
      "\n",
      "    accuracy                           0.83     10807\n",
      "   macro avg       0.83      0.82      0.83     10807\n",
      "weighted avg       0.83      0.83      0.83     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0087\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78      4909\n",
      "           1       0.79      0.89      0.84      5898\n",
      "\n",
      "    accuracy                           0.81     10807\n",
      "   macro avg       0.82      0.81      0.81     10807\n",
      "weighted avg       0.82      0.81      0.81     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_m, X_train_m, X_test_m, y_train_m, y_test_m, median_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_m, X_train_m, X_test_m, y_train_m, y_test_m, median_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_m, X_train_m, X_test_m, y_train_m, y_test_m, median_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633f095-ebbc-497f-8bf4-fe6398ece64e",
   "metadata": {},
   "source": [
    "### 4.1.3 Occupancy Detection Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5cb642-6275-4386-bc4e-4fc92db353c8",
   "metadata": {},
   "source": [
    "**- MEAN IMPUTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "6fbe41a6-3bd2-4771-a4e3-707e44e4355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1693\n",
      "           1       0.92      0.94      0.93       972\n",
      "\n",
      "    accuracy                           0.95      2665\n",
      "   macro avg       0.94      0.94      0.94      2665\n",
      "weighted avg       0.95      0.95      0.95      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0077\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1693\n",
      "           1       0.91      0.95      0.93       972\n",
      "\n",
      "    accuracy                           0.95      2665\n",
      "   macro avg       0.94      0.95      0.95      2665\n",
      "weighted avg       0.95      0.95      0.95      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0090\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      1693\n",
      "           1       0.92      0.60      0.72       972\n",
      "\n",
      "    accuracy                           0.83      2665\n",
      "   macro avg       0.86      0.78      0.80      2665\n",
      "weighted avg       0.85      0.83      0.82      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean_imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_o, X_train_o, X_test_o, y_train_o, y_test_o, mean_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_o, X_train_o, X_test_o, y_train_o, y_test_o, mean_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_o, X_train_o, X_test_o, y_train_o, y_test_o, mean_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95e330-579e-4b6d-a847-a06c5aeeb4d1",
   "metadata": {},
   "source": [
    "**- MEDIAN IMPUTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "1878f4ab-3e2f-42ee-9022-259d6523ebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1693\n",
      "           1       0.91      0.95      0.93       972\n",
      "\n",
      "    accuracy                           0.95      2665\n",
      "   macro avg       0.94      0.95      0.95      2665\n",
      "weighted avg       0.95      0.95      0.95      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0056\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1693\n",
      "           1       0.91      0.96      0.93       972\n",
      "\n",
      "    accuracy                           0.95      2665\n",
      "   macro avg       0.94      0.95      0.95      2665\n",
      "weighted avg       0.95      0.95      0.95      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0091\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      1693\n",
      "           1       0.92      0.60      0.72       972\n",
      "\n",
      "    accuracy                           0.83      2665\n",
      "   macro avg       0.86      0.78      0.80      2665\n",
      "weighted avg       0.85      0.83      0.82      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\")\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_o, X_train_o, X_test_o, y_train_o, y_test_o, median_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_o, X_train_o, X_test_o, y_train_o, y_test_o, median_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_o, X_train_o, X_test_o, y_train_o, y_test_o, median_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c681d9c2-8545-4f7a-a9fe-72a7d8bd65c1",
   "metadata": {},
   "source": [
    "## 4.2 **K-Nearest Neighbors Imputation**\n",
    "Different approach called KNN Imputation, using n_neighbors=5, fills missing data based on values from the nearest neighbors in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7cb630-0e81-4f74-b2a0-7dc291654aae",
   "metadata": {},
   "source": [
    "### 4.2.1 Autism Screening Adult Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "22686c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       126\n",
      "           1       0.96      0.89      0.93        57\n",
      "\n",
      "    accuracy                           0.96       183\n",
      "   macro avg       0.96      0.94      0.95       183\n",
      "weighted avg       0.96      0.96      0.96       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0017\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       126\n",
      "           1       0.93      0.95      0.94        57\n",
      "\n",
      "    accuracy                           0.96       183\n",
      "   macro avg       0.95      0.96      0.96       183\n",
      "weighted avg       0.96      0.96      0.96       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0020\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       126\n",
      "           1       0.96      0.84      0.90        57\n",
      "\n",
      "    accuracy                           0.94       183\n",
      "   macro avg       0.95      0.91      0.93       183\n",
      "weighted avg       0.94      0.94      0.94       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_a, X_train_a, X_test_a, y_train_a, y_test_a, knn_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_a, X_train_a, X_test_a, y_train_a, y_test_a, knn_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_a, X_train_a, X_test_a, y_train_a, y_test_a, knn_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fdc9fb-a900-41a1-b23e-d3f6ff335cb3",
   "metadata": {},
   "source": [
    "### 4.2.2 Mushroom Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "cc7b8cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4909\n",
      "           1       0.89      0.88      0.88      5898\n",
      "\n",
      "    accuracy                           0.87     10807\n",
      "   macro avg       0.87      0.87      0.87     10807\n",
      "weighted avg       0.87      0.87      0.87     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0031\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83      4909\n",
      "           1       0.86      0.87      0.86      5898\n",
      "\n",
      "    accuracy                           0.85     10807\n",
      "   macro avg       0.85      0.85      0.85     10807\n",
      "weighted avg       0.85      0.85      0.85     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0069\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77      4909\n",
      "           1       0.79      0.89      0.83      5898\n",
      "\n",
      "    accuracy                           0.81     10807\n",
      "   macro avg       0.81      0.80      0.80     10807\n",
      "weighted avg       0.81      0.81      0.80     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_m, X_train_m, X_test_m, y_train_m, y_test_m, knn_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_m, X_train_m, X_test_m, y_train_m, y_test_m, knn_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_m, X_train_m, X_test_m, y_train_m, y_test_m, knn_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c9a25-d2a5-48c0-979e-060a733f1532",
   "metadata": {},
   "source": [
    "### 4.2.3 Occupancy Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "8ab9888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      1693\n",
      "           1       0.95      1.00      0.97       972\n",
      "\n",
      "    accuracy                           0.98      2665\n",
      "   macro avg       0.97      0.98      0.98      2665\n",
      "weighted avg       0.98      0.98      0.98      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0004\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1693\n",
      "           1       0.95      0.89      0.92       972\n",
      "\n",
      "    accuracy                           0.94      2665\n",
      "   macro avg       0.95      0.93      0.94      2665\n",
      "weighted avg       0.94      0.94      0.94      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0036\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      1693\n",
      "           1       0.92      0.60      0.72       972\n",
      "\n",
      "    accuracy                           0.83      2665\n",
      "   macro avg       0.86      0.78      0.80      2665\n",
      "weighted avg       0.85      0.83      0.82      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_o, X_train_o, X_test_o, y_train_o, y_test_o, knn_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_o, X_train_o, X_test_o, y_train_o, y_test_o, knn_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_o, X_train_o, X_test_o, y_train_o, y_test_o, knn_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e98466-34fc-4b9a-b152-e5401951d862",
   "metadata": {},
   "source": [
    "## 4.3 **Multiple Imputation MICE**\n",
    "Multiple Imputation involves modeling each feature with missing data conditionally on other features. The process is repeated max_iter = 100 times to enhance imputation stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd1ff5-837e-4c4e-ba9a-10180b65f005",
   "metadata": {},
   "source": [
    "### 4.3.1 Autism Screening Adult Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "a3d52278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       126\n",
      "           1       0.96      0.91      0.94        57\n",
      "\n",
      "    accuracy                           0.96       183\n",
      "   macro avg       0.96      0.95      0.95       183\n",
      "weighted avg       0.96      0.96      0.96       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0018\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       126\n",
      "           1       0.93      0.93      0.93        57\n",
      "\n",
      "    accuracy                           0.96       183\n",
      "   macro avg       0.95      0.95      0.95       183\n",
      "weighted avg       0.96      0.96      0.96       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0020\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       126\n",
      "           1       0.96      0.84      0.90        57\n",
      "\n",
      "    accuracy                           0.94       183\n",
      "   macro avg       0.95      0.91      0.93       183\n",
      "weighted avg       0.94      0.94      0.94       183\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mice_imputer = IterativeImputer(max_iter=100)\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_a, X_train_a, X_test_a, y_train_a, y_test_a, mice_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_a, X_train_a, X_test_a, y_train_a, y_test_a, mice_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_a, X_train_a, X_test_a, y_train_a, y_test_a, mice_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c2182-a156-4a6e-b237-ef4a6700ab1e",
   "metadata": {},
   "source": [
    "### 4.3.2 Mushroom Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "eb122cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4909\n",
      "           1       0.87      0.87      0.87      5898\n",
      "\n",
      "    accuracy                           0.86     10807\n",
      "   macro avg       0.86      0.86      0.86     10807\n",
      "weighted avg       0.86      0.86      0.86     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0081\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82      4909\n",
      "           1       0.84      0.87      0.86      5898\n",
      "\n",
      "    accuracy                           0.84     10807\n",
      "   macro avg       0.84      0.84      0.84     10807\n",
      "weighted avg       0.84      0.84      0.84     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0085\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78      4909\n",
      "           1       0.79      0.89      0.84      5898\n",
      "\n",
      "    accuracy                           0.81     10807\n",
      "   macro avg       0.82      0.80      0.81     10807\n",
      "weighted avg       0.82      0.81      0.81     10807\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mice_imputer = IterativeImputer(max_iter=100)\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_m, X_train_m, X_test_m, y_train_m, y_test_m, mice_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_m, X_train_m, X_test_m, y_train_m, y_test_m, mice_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_m, X_train_m, X_test_m, y_train_m, y_test_m, mice_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defad2f4-723c-45fd-bcb6-5ccee9ec166c",
   "metadata": {},
   "source": [
    "### 4.3.3 Occupancy Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "ef4ffa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1693\n",
      "           1       0.94      0.95      0.95       972\n",
      "\n",
      "    accuracy                           0.96      2665\n",
      "   macro avg       0.96      0.96      0.96      2665\n",
      "weighted avg       0.96      0.96      0.96      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MCAR Imputation: 0.0036\n",
      "\n",
      "MAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      1693\n",
      "           1       0.97      0.92      0.94       972\n",
      "\n",
      "    accuracy                           0.96      2665\n",
      "   macro avg       0.96      0.95      0.95      2665\n",
      "weighted avg       0.96      0.96      0.96      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MAR Imputation: 0.0097\n",
      "\n",
      "MNAR Results:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88      1693\n",
      "           1       0.92      0.60      0.72       972\n",
      "\n",
      "    accuracy                           0.83      2665\n",
      "   macro avg       0.86      0.78      0.80      2665\n",
      "weighted avg       0.85      0.83      0.82      2665\n",
      "\n",
      "Mean Absolute Error (MAE) of MNAR Imputation: 0.0110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mice_imputer = IterativeImputer(max_iter=100)\n",
    "#MCAR\n",
    "y_pred, report, mae = run_svm(X_MCAR_o, X_train_o, X_test_o, y_train_o, y_test_o, mice_imputer)\n",
    "print(\"MCAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MCAR Imputation: {mae:.4f}\\n\")\n",
    "#MAR\n",
    "y_pred, report, mae = run_svm(X_MAR_o, X_train_o, X_test_o, y_train_o, y_test_o, mice_imputer)\n",
    "print(\"MAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MAR Imputation: {mae:.4f}\\n\")\n",
    "#MNAR\n",
    "y_pred, report, mae = run_svm(X_MNAR_o, X_train_o, X_test_o, y_train_o, y_test_o, mice_imputer)\n",
    "print(\"MNAR Results:\\n\")\n",
    "print(report)\n",
    "print(f\"Mean Absolute Error (MAE) of MNAR Imputation: {mae:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
